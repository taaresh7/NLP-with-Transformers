{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Imports and Version","metadata":{}},{"cell_type":"code","source":"import transformers, datasets\ntransformers.__version__, datasets.__version__","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T07:09:52.577279Z","iopub.execute_input":"2024-06-06T07:09:52.577975Z","iopub.status.idle":"2024-06-06T07:09:59.238912Z","shell.execute_reply.started":"2024-06-06T07:09:52.577941Z","shell.execute_reply":"2024-06-06T07:09:59.237864Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"('4.39.3', '2.18.0')"},"metadata":{}}]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndata = load_dataset(\"conll2003\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:09:59.241087Z","iopub.execute_input":"2024-06-06T07:09:59.241882Z","iopub.status.idle":"2024-06-06T07:10:11.130406Z","shell.execute_reply.started":"2024-06-06T07:09:59.241847Z","shell.execute_reply":"2024-06-06T07:10:11.129439Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0309ed20ece34c76a68ac57910cc3c9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/12.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3536abed9814692b90551952ec1c3b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ab97df5dfbb41a8a103f56f460fc8f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edb746533d594573851e988e8da1ed0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dec4a2abf714ec1aeb3477eb165c165"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e25d9ce8ea4d490e87f202ecf16c439a"}},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:11.131514Z","iopub.execute_input":"2024-06-06T07:10:11.131873Z","iopub.status.idle":"2024-06-06T07:10:11.137710Z","shell.execute_reply.started":"2024-06-06T07:10:11.131840Z","shell.execute_reply":"2024-06-06T07:10:11.136859Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data['train'][0] # tokens here are not exactly tokens but subwords","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:11.139843Z","iopub.execute_input":"2024-06-06T07:10:11.140109Z","iopub.status.idle":"2024-06-06T07:10:11.155138Z","shell.execute_reply.started":"2024-06-06T07:10:11.140086Z","shell.execute_reply":"2024-06-06T07:10:11.154293Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"data[\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:11.156349Z","iopub.execute_input":"2024-06-06T07:10:11.156713Z","iopub.status.idle":"2024-06-06T07:10:11.168192Z","shell.execute_reply.started":"2024-06-06T07:10:11.156665Z","shell.execute_reply":"2024-06-06T07:10:11.167266Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'id': Value(dtype='string', id=None),\n 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None),\n 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None),\n 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"data[\"train\"].features['ner_tags']","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:11.169493Z","iopub.execute_input":"2024-06-06T07:10:11.169783Z","iopub.status.idle":"2024-06-06T07:10:11.177873Z","shell.execute_reply.started":"2024-06-06T07:10:11.169760Z","shell.execute_reply":"2024-06-06T07:10:11.177123Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"},"metadata":{}}]},{"cell_type":"code","source":"# saving for later \nlabel_names = data[\"train\"].features[\"ner_tags\"].feature.names","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:11.178829Z","iopub.execute_input":"2024-06-06T07:10:11.179105Z","iopub.status.idle":"2024-06-06T07:10:11.187728Z","shell.execute_reply.started":"2024-06-06T07:10:11.179070Z","shell.execute_reply":"2024-06-06T07:10:11.186906Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"distilbert-base-cased\"\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:11.188679Z","iopub.execute_input":"2024-06-06T07:10:11.188975Z","iopub.status.idle":"2024-06-06T07:10:12.873269Z","shell.execute_reply.started":"2024-06-06T07:10:11.188953Z","shell.execute_reply":"2024-06-06T07:10:12.872466Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45208fcc4d184bfb9e3fd1d444d2fe1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e089af61758b4703b087dd102099280b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a4c6bc3859143b2ac091abcee3a1b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81c4162c47474a4995f66ac70a551a6c"}},"metadata":{}}]},{"cell_type":"code","source":"idx = 0\nt = tokenizer(data[\"train\"][idx][\"tokens\"], is_split_into_words=True)  # is_split_into_words = True because the data is already in he tokens \nt","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.874359Z","iopub.execute_input":"2024-06-06T07:10:12.874655Z","iopub.status.idle":"2024-06-06T07:10:12.883185Z","shell.execute_reply.started":"2024-06-06T07:10:12.874631Z","shell.execute_reply":"2024-06-06T07:10:12.882238Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"data[\"train\"].features[\"ner_tags\"].feature.names","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.886755Z","iopub.execute_input":"2024-06-06T07:10:12.887044Z","iopub.status.idle":"2024-06-06T07:10:12.894267Z","shell.execute_reply.started":"2024-06-06T07:10:12.887016Z","shell.execute_reply":"2024-06-06T07:10:12.893355Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}]},{"cell_type":"code","source":"data[\"train\"][idx][\"ner_tags\"]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.895398Z","iopub.execute_input":"2024-06-06T07:10:12.895763Z","iopub.status.idle":"2024-06-06T07:10:12.904908Z","shell.execute_reply.started":"2024-06-06T07:10:12.895729Z","shell.execute_reply":"2024-06-06T07:10:12.904043Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[3, 0, 7, 0, 0, 0, 7, 0, 0]"},"metadata":{}}]},{"cell_type":"code","source":"type(t), t.tokens()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.905908Z","iopub.execute_input":"2024-06-06T07:10:12.906165Z","iopub.status.idle":"2024-06-06T07:10:12.915345Z","shell.execute_reply.started":"2024-06-06T07:10:12.906143Z","shell.execute_reply":"2024-06-06T07:10:12.914452Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(transformers.tokenization_utils_base.BatchEncoding,\n ['[CLS]',\n  'EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'la',\n  '##mb',\n  '.',\n  '[SEP]'])"},"metadata":{}}]},{"cell_type":"code","source":"t.word_ids()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.916543Z","iopub.execute_input":"2024-06-06T07:10:12.916815Z","iopub.status.idle":"2024-06-06T07:10:12.926064Z","shell.execute_reply.started":"2024-06-06T07:10:12.916792Z","shell.execute_reply":"2024-06-06T07:10:12.925256Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Tokens not aligned when the tokenizers breaks a words into multiple tokens ","metadata":{}},{"cell_type":"code","source":"# code to align targets \ndef align_targets(label_names, word_ids, ner_tags):\n    new_ner = []\n    to_add = None\n    last_word_id = 0\n    for i in word_ids:\n        if i is None:\n            to_add = -100\n        elif last_word_id == i:\n            to_add = label_names[ner_tags[last_word_id]]\n            to_add = to_add.replace(\"B\", \"I\")\n            to_add = label_names.index(to_add)\n        else:\n#            print(ner_tags[i])\n            to_add = label_names[ner_tags[i]]\n            to_add = label_names.index(to_add)\n\n        last_word_id = i\n        new_ner.append(to_add)\n\n    return new_ner","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.927107Z","iopub.execute_input":"2024-06-06T07:10:12.927894Z","iopub.status.idle":"2024-06-06T07:10:12.935504Z","shell.execute_reply.started":"2024-06-06T07:10:12.927860Z","shell.execute_reply":"2024-06-06T07:10:12.934629Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"idx = 18\nlabels = data['train'][idx]['ner_tags']\nt = tokenizer(data[\"train\"][idx][\"tokens\"], is_split_into_words=True)\nword_ids = t.word_ids()\n\naligned_targets = align_targets(label_names, word_ids, labels)\naligned_targets","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.936467Z","iopub.execute_input":"2024-06-06T07:10:12.936742Z","iopub.status.idle":"2024-06-06T07:10:12.947476Z","shell.execute_reply.started":"2024-06-06T07:10:12.936703Z","shell.execute_reply":"2024-06-06T07:10:12.946659Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[-100, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]"},"metadata":{}}]},{"cell_type":"code","source":"word_ids = t.word_ids(0)\nword_ids","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.948451Z","iopub.execute_input":"2024-06-06T07:10:12.948735Z","iopub.status.idle":"2024-06-06T07:10:12.956459Z","shell.execute_reply.started":"2024-06-06T07:10:12.948703Z","shell.execute_reply":"2024-06-06T07:10:12.955555Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[None, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, None]"},"metadata":{}}]},{"cell_type":"code","source":"aligned_labels = [label_names[t] if t >= 0 else None for t in aligned_targets]\nfor x, y in zip(t.tokens(), aligned_labels):\n    print(f\"{x}\\t{y}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.957459Z","iopub.execute_input":"2024-06-06T07:10:12.957731Z","iopub.status.idle":"2024-06-06T07:10:12.966296Z","shell.execute_reply.started":"2024-06-06T07:10:12.957701Z","shell.execute_reply":"2024-06-06T07:10:12.965510Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[CLS]\tNone\nGermany\tB-LOC\nimported\tO\n47\tO\n,\tO\n600\tO\nsheep\tO\nfrom\tO\nBritain\tB-LOC\nlast\tO\nyear\tO\n,\tO\nnearly\tO\nhalf\tO\nof\tO\ntotal\tO\nimports\tO\n.\tO\n[SEP]\tNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# make up a fake input just to test it\nwords = [\n  '[CLS]', 'Ger', '##man', 'call', 'to', 'boycott', 'Micro', '##soft', '[SEP]']\nword_ids = [None, 0, 0, 1, 2, 3, 4, 4, None]\nlabels = [7, 0, 0, 0, 3]\n\naligned_targets = align_targets(label_names, word_ids, labels)\nprint(aligned_targets)\nprint(\"\\n\")\n\naligned_labels = [label_names[t] if t >= 0 else None for t in aligned_targets]\nfor x, y in zip(words, aligned_labels):\n    print(f\"{x}\\t{y}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.967300Z","iopub.execute_input":"2024-06-06T07:10:12.967589Z","iopub.status.idle":"2024-06-06T07:10:12.976523Z","shell.execute_reply.started":"2024-06-06T07:10:12.967565Z","shell.execute_reply":"2024-06-06T07:10:12.975635Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[-100, 7, 8, 0, 0, 0, 3, 4, -100]\n\n\n\n[CLS]\tNone\nGer\tB-MISC\n##man\tI-MISC\ncall\tO\nto\tO\nboycott\tO\nMicro\tB-ORG\n##soft\tI-ORG\n[SEP]\tNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Tokenize and align ","metadata":{}},{"cell_type":"code","source":"# tokenize both inputs and targets\ndef tokenize_fn(batch):\n  # tokenize the input sequence first\n  # this populates input_ids, attention_mask, etc.\n    tokenized_inputs = tokenizer(\n                batch['tokens'], truncation=True, is_split_into_words=True)\n\n    labels_batch = batch['ner_tags'] # original targets\n    aligned_labels_batch = []\n    for i, labels in enumerate(labels_batch):\n        word_ids = tokenized_inputs.word_ids(i)\n        aligned_labels_batch.append(align_targets(label_names, word_ids, labels))\n        \n  # recall: the 'target' must be stored in key called 'labels'\n    tokenized_inputs['labels'] = aligned_labels_batch\n\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.977566Z","iopub.execute_input":"2024-06-06T07:10:12.977836Z","iopub.status.idle":"2024-06-06T07:10:12.991492Z","shell.execute_reply.started":"2024-06-06T07:10:12.977814Z","shell.execute_reply":"2024-06-06T07:10:12.990556Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# want to remove these from model inputs - they are neither inputs nor targets\ndata[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:12.992543Z","iopub.execute_input":"2024-06-06T07:10:12.992908Z","iopub.status.idle":"2024-06-06T07:10:13.005332Z","shell.execute_reply.started":"2024-06-06T07:10:12.992885Z","shell.execute_reply":"2024-06-06T07:10:13.004470Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets = data.map(\n  tokenize_fn,\n  batched=True,\n  remove_columns=data[\"train\"].column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:13.006347Z","iopub.execute_input":"2024-06-06T07:10:13.006595Z","iopub.status.idle":"2024-06-06T07:10:15.596699Z","shell.execute_reply.started":"2024-06-06T07:10:13.006574Z","shell.execute_reply":"2024-06-06T07:10:15.595830Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"411408450f7d480a9d8e54d9bac752ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5019c940c1ce47d29643f37761d1ca04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c379315ac8f744d29582f6b6e45c8254"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:15.597670Z","iopub.execute_input":"2024-06-06T07:10:15.597959Z","iopub.status.idle":"2024-06-06T07:10:15.603839Z","shell.execute_reply.started":"2024-06-06T07:10:15.597935Z","shell.execute_reply":"2024-06-06T07:10:15.602860Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Data Collator","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:21:41.201166Z","iopub.execute_input":"2024-06-06T08:21:41.201495Z","iopub.status.idle":"2024-06-06T08:21:41.206259Z","shell.execute_reply.started":"2024-06-06T08:21:41.201466Z","shell.execute_reply":"2024-06-06T08:21:41.205387Z"}}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:15.604952Z","iopub.execute_input":"2024-06-06T07:10:15.605225Z","iopub.status.idle":"2024-06-06T07:10:25.766628Z","shell.execute_reply.started":"2024-06-06T07:10:15.605203Z","shell.execute_reply":"2024-06-06T07:10:25.765854Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"2024-06-06 07:10:17.766471: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-06 07:10:17.766573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-06 07:10:17.905098: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"data_collator","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:25.767791Z","iopub.execute_input":"2024-06-06T07:10:25.768352Z","iopub.status.idle":"2024-06-06T07:10:25.776539Z","shell.execute_reply.started":"2024-06-06T07:10:25.768326Z","shell.execute_reply":"2024-06-06T07:10:25.775728Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"DataCollatorForTokenClassification(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}, padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets[\"train\"][0:2]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:25.777627Z","iopub.execute_input":"2024-06-06T07:10:25.777933Z","iopub.status.idle":"2024-06-06T07:10:25.826119Z","shell.execute_reply.started":"2024-06-06T07:10:25.777909Z","shell.execute_reply":"2024-06-06T07:10:25.824708Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[101,\n   7270,\n   22961,\n   1528,\n   1840,\n   1106,\n   21423,\n   1418,\n   2495,\n   12913,\n   119,\n   102],\n  [101, 1943, 14428, 102]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]],\n 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100], [-100, 1, 2, -100]]}"},"metadata":{}}]},{"cell_type":"code","source":"[tokenized_datasets[\"train\"][i] for i in range(2)]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:25.827450Z","iopub.execute_input":"2024-06-06T07:10:25.827967Z","iopub.status.idle":"2024-06-06T07:10:25.839226Z","shell.execute_reply.started":"2024-06-06T07:10:25.827937Z","shell.execute_reply":"2024-06-06T07:10:25.838261Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'input_ids': [101,\n   7270,\n   22961,\n   1528,\n   1840,\n   1106,\n   21423,\n   1418,\n   2495,\n   12913,\n   119,\n   102],\n  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n  'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]},\n {'input_ids': [101, 1943, 14428, 102],\n  'attention_mask': [1, 1, 1, 1],\n  'labels': [-100, 1, 2, -100]}]"},"metadata":{}}]},{"cell_type":"code","source":"# example\nbatch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\nbatch[\"labels\"]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:25.840426Z","iopub.execute_input":"2024-06-06T07:10:25.840776Z","iopub.status.idle":"2024-06-06T07:10:25.883469Z","shell.execute_reply.started":"2024-06-06T07:10:25.840734Z","shell.execute_reply":"2024-06-06T07:10:25.882613Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"},"metadata":{}}]},{"cell_type":"code","source":"batch","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:25.887913Z","iopub.execute_input":"2024-06-06T07:10:25.888243Z","iopub.status.idle":"2024-06-06T07:10:25.895557Z","shell.execute_reply.started":"2024-06-06T07:10:25.888219Z","shell.execute_reply":"2024-06-06T07:10:25.894724Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[  101,  7270, 22961,  1528,  1840,  1106, 21423,  1418,  2495, 12913,\n           119,   102],\n        [  101,  1943, 14428,   102,     0,     0,     0,     0,     0,     0,\n             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Metric","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:22:18.804953Z","iopub.execute_input":"2024-06-06T08:22:18.805324Z","iopub.status.idle":"2024-06-06T08:22:18.809265Z","shell.execute_reply.started":"2024-06-06T08:22:18.805293Z","shell.execute_reply":"2024-06-06T08:22:18.808354Z"}}},{"cell_type":"code","source":"!pip install seqeval\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:25.896653Z","iopub.execute_input":"2024-06-06T07:10:25.897029Z","iopub.status.idle":"2024-06-06T07:10:42.127532Z","shell.execute_reply.started":"2024-06-06T07:10:25.896974Z","shell.execute_reply":"2024-06-06T07:10:42.126399Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=c4714271cac006f7e26706ec6126a0cba568afc0fe6d6235a8d9982b9ff7ee81\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:42.129274Z","iopub.execute_input":"2024-06-06T07:10:42.130265Z","iopub.status.idle":"2024-06-06T07:10:42.658051Z","shell.execute_reply.started":"2024-06-06T07:10:42.130212Z","shell.execute_reply":"2024-06-06T07:10:42.657186Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3097260500.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"seqeval\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43285b15360d41fa908c9ffa9c26cd77"}},"metadata":{}}]},{"cell_type":"code","source":"# test it out\nmetric.compute(\n    predictions=[['O', 'O', 'I-ORG', 'B-MISC']],\n    references=[['O', 'B-ORG', 'I-ORG', 'B-MISC']])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:42.659203Z","iopub.execute_input":"2024-06-06T07:10:42.659520Z","iopub.status.idle":"2024-06-06T07:10:42.678615Z","shell.execute_reply.started":"2024-06-06T07:10:42.659488Z","shell.execute_reply":"2024-06-06T07:10:42.677805Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n 'overall_precision': 0.5,\n 'overall_recall': 0.5,\n 'overall_f1': 0.5,\n 'overall_accuracy': 0.75}"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(logits_and_labels):\n    logits, labels = logits_and_labels\n    preds = np.argmax(logits, axis=-1)\n\n    # remove -100 from labels and predictions\n    # and convert the label_ids to label names\n    str_labels = [\n    [label_names[t] for t in label if t != -100] for label in labels\n    ]\n\n    # do the same for predictions whenever true label is -100\n    str_preds = [\n    [label_names[p] for p, t in zip(pred, targ) if t != -100] \\\n      for pred, targ in zip(preds, labels)\n    ]\n\n    the_metrics = metric.compute(predictions=str_preds, references=str_labels)\n    return {\n            'precision': the_metrics['overall_precision'],\n            'recall': the_metrics['overall_recall'],\n            'f1': the_metrics['overall_f1'],\n            'accuracy': the_metrics['overall_accuracy'],\n            }","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:42.679757Z","iopub.execute_input":"2024-06-06T07:10:42.680037Z","iopub.status.idle":"2024-06-06T07:10:42.687060Z","shell.execute_reply.started":"2024-06-06T07:10:42.680005Z","shell.execute_reply":"2024-06-06T07:10:42.686248Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Model and Trainer","metadata":{}},{"cell_type":"code","source":"id2label = {k: v for k, v in enumerate(label_names)}\nlabel2id = {v: k for k, v in id2label.items()}\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:42.688240Z","iopub.execute_input":"2024-06-06T07:10:42.688495Z","iopub.status.idle":"2024-06-06T07:10:42.700839Z","shell.execute_reply.started":"2024-06-06T07:10:42.688473Z","shell.execute_reply":"2024-06-06T07:10:42.700051Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:42.702212Z","iopub.execute_input":"2024-06-06T07:10:42.702667Z","iopub.status.idle":"2024-06-06T07:10:45.158169Z","shell.execute_reply.started":"2024-06-06T07:10:42.702637Z","shell.execute_reply":"2024-06-06T07:10:45.157388Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c2a31a170b44edaa31ad966285198c4"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    \"distilbert-finetuned-ner\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,report_to = \"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:45.159493Z","iopub.execute_input":"2024-06-06T07:10:45.159885Z","iopub.status.idle":"2024-06-06T07:10:45.247227Z","shell.execute_reply.started":"2024-06-06T07:10:45.159851Z","shell.execute_reply":"2024-06-06T07:10:45.246470Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:10:45.248394Z","iopub.execute_input":"2024-06-06T07:10:45.249042Z","iopub.status.idle":"2024-06-06T07:14:16.380701Z","shell.execute_reply.started":"2024-06-06T07:10:45.249009Z","shell.execute_reply":"2024-06-06T07:14:16.379747Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5268/5268 03:29, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.092300</td>\n      <td>0.082346</td>\n      <td>0.878734</td>\n      <td>0.915853</td>\n      <td>0.896910</td>\n      <td>0.977130</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.046200</td>\n      <td>0.074711</td>\n      <td>0.910546</td>\n      <td>0.928475</td>\n      <td>0.919423</td>\n      <td>0.981751</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.027800</td>\n      <td>0.074716</td>\n      <td>0.914145</td>\n      <td>0.935375</td>\n      <td>0.924638</td>\n      <td>0.982501</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5268, training_loss=0.08069954202676598, metrics={'train_runtime': 210.5743, 'train_samples_per_second': 200.039, 'train_steps_per_second': 25.017, 'total_flos': 460431563935266.0, 'train_loss': 0.08069954202676598, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('ner_model_1')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:14:41.127303Z","iopub.execute_input":"2024-06-06T07:14:41.127657Z","iopub.status.idle":"2024-06-06T07:14:41.688363Z","shell.execute_reply.started":"2024-06-06T07:14:41.127632Z","shell.execute_reply":"2024-06-06T07:14:41.687594Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nner = pipeline(\n  \"token-classification\",\n  model='/kaggle/working/ner_model_1',\n  aggregation_strategy=\"simple\",\n  device=0,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:16:41.059963Z","iopub.execute_input":"2024-06-06T07:16:41.060621Z","iopub.status.idle":"2024-06-06T07:16:41.849881Z","shell.execute_reply.started":"2024-06-06T07:16:41.060591Z","shell.execute_reply":"2024-06-06T07:16:41.848933Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"s = \"Bill Gates was the CEO of Microsoft in Seattle, Washington.\"\nner(s)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:17:11.980374Z","iopub.execute_input":"2024-06-06T07:17:11.981194Z","iopub.status.idle":"2024-06-06T07:17:11.997023Z","shell.execute_reply.started":"2024-06-06T07:17:11.981160Z","shell.execute_reply":"2024-06-06T07:17:11.996149Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"[{'entity_group': 'PER',\n  'score': 0.99921405,\n  'word': 'Bill Gates',\n  'start': 0,\n  'end': 10},\n {'entity_group': 'ORG',\n  'score': 0.99824214,\n  'word': 'Microsoft',\n  'start': 26,\n  'end': 35},\n {'entity_group': 'LOC',\n  'score': 0.99734527,\n  'word': 'Seattle',\n  'start': 39,\n  'end': 46},\n {'entity_group': 'LOC',\n  'score': 0.9975376,\n  'word': 'Washington',\n  'start': 48,\n  'end': 58}]"},"metadata":{}}]}]}