{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b8d24d-5291-40f5-9506-659817519be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.22.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c628fd5-1a29-4079-b287-d51be57ddb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651ae509-e73a-4bb1-bef6-f593bf031f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11aeb850-0916-47ad-bb48-9e1455d33243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2088, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5748e50d-02d5-4b85-a9d7-7234d2d6024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"hello world\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea2bcccf-4475-437c-8346-4867ed1ff4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7592, 2088]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3cd7736c-b846-4f51-81be-845aadb324b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "614a7304-13b3-4b54-8d29-5a7a12210775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0129186d-3311-4892-b49d-8ef276ee11f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 2088, 102]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(\"hello world\")\n",
    "ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "848c12bb-4269-405f-9d13-97b885050d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'hello', 'world', '[SEP]']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80d0520b-d691-4971-91e4-3554e3651f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hello world [SEP]'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4fa2172f-f050-4f64-8a8d-d6816e4ad1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2088, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer(\"hello world\")\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5ff3059-714b-4ccf-9035-e67a16ad6753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2066, 8870, 1012, 102], [101, 2079, 2017, 2066, 8870, 2205, 1029, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "  \"I like cats.\",\n",
    "  \"Do you like cats too?\",\n",
    "]\n",
    "tokenizer(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc36dc1d-27e8-45a8-89c0-803e47c16a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e548c1-8c74-472d-830f-87410647871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs = model(**model_inputs)\n",
    "## will return in AttributeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b79b91a7-83d1-45bf-8d72-e8580750db3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 2088,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer(\"hello world\", return_tensors='pt')\n",
    "model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17778968-1e1b-475c-bc59-acf4213cda36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0010,  0.0960]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the default was to create a binary classifier!\n",
    "outputs = model(**model_inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d80d58b9-1620-4432-b198-90585c45f444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f1b9faf-c120-46fc-ace8-06214ed99d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0207, -0.0510,  0.3296]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**model_inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a0d0aab-f19e-4993-aec1-1b63f67fd5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02069107, -0.05102777,  0.32962486]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits\n",
    "outputs.logits.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d765d6e-d708-4b9c-80e2-9b4351dc2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "  \"I like cats.\",\n",
    "  \"Do you like cats too?\",\n",
    "]\n",
    "model_inputs = tokenizer(data, return_tensors='pt')\n",
    "model_inputs\n",
    "# will give value error \n",
    "# because diff tensor size, need to pad and truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9774c18-8dcb-4947-9c9a-cb7c1a5f7c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 2066, 8870, 1012,  102,    0,    0],\n",
       "        [ 101, 2079, 2017, 2066, 8870, 2205, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer(\n",
    "    data, padding=True, truncation=True, return_tensors='pt')\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "46cd65a1-17ae-4339-8f87-418a8625ed93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1045, 2066, 8870, 1012,  102,    0,    0],\n",
       "        [ 101, 2079, 2017, 2066, 8870, 2205, 1029,  102]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a261bae4-986d-44b9-85dd-98be1f163bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba10c4c3-4fa9-464d-afed-53f545479252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5256ab78-cf33-46ab-9866-cca99d48c523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0371,  0.1122,  0.2985],\n",
       "        [-0.0471,  0.0894,  0.2821]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**model_inputs)\n",
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
